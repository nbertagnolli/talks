{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.optimizers import SGD, Adam\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   1  How to check if an uploaded file is an image w...   \n",
       "1   2  How can I prevent firefox from closing when I ...   \n",
       "2   3           R Error Invalid type (list) for variable   \n",
       "3   4      How do I replace special characters in a URL?   \n",
       "4   5               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv('Train.csv', nrows=20000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_length = 350  # length of input sequences to the model\n",
    "n_top_tags = 8  # n most prevelant tags to try to predict\n",
    "vocab_size = 2000  # How many distinct tokens to take\n",
    "char_model = False  # type of model to train (character or word)\n",
    "batch_size = 128\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['php image-processing file-upload upload mime-types', 'firefox', 'r matlab machine-learning', 'c# url encoding', 'php api file-get-contents', 'proxy active-directory jmeter', 'core-plot', 'c# asp.net windows-phone-7', '.net javascript code-generation', 'sql variables parameters procedure calls', '.net obfuscation reflector', 'algorithm language-agnostic random', 'postfix migration mdaemon', 'documentation latex3 expl3', 'windows-7', 'php url-routing conventions', 'r temporary-files', 'wpf binding', 'javascript code-generation playframework minify', 'php xml hash multidimensional-array simplexml-load-string', 'medical-science cancer healthcare', 'c# .net linq', 'actionscript-3 flex flex3', 'iis', 'c# linq string enumeration']\n",
      "===================================================================================================================\n",
      "[\"<p>I'd like to check if an uploaded file is an image file (e.g png, jpg, jpeg, gif, bmp) or another file. The problem is that I'm using Uploadify to upload the files, which changes the mime type and gives a 'text/octal' or something as the mime type, no matter which file type you upload.</p>\\n\\n<p>Is there a way to check if the uploaded file is an image apart from checking the file extension using PHP?</p>\\n\", '<p>In my favorite editor (vim), I regularly use ctrl-w to execute a certain action. Now, it quite often happens to me that firefox is the active window (on windows) while I still look at vim (thinking vim is the active window) and press ctrl-w which closes firefox. This is not what I want. Is there a way to stop ctrl-w from closing firefox?</p>\\n\\n<p>Rene</p>\\n']\n"
     ]
    }
   ],
   "source": [
    "# Convert the tags and texts to lists for the keras tokenizer\n",
    "tag_list = data['Tags'].tolist()\n",
    "text_list = data['Body'].tolist()\n",
    "\n",
    "print(tag_list[:25])\n",
    "print(\"=\"*115)\n",
    "print(text_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer(num_words=n_top_tags + 1)\n",
    "tag_tokenizer.fit_on_texts(tag_list)\n",
    "tag_matrix = tag_tokenizer.texts_to_matrix(tag_list)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['c', 'net', 'java', 'android', 'php', 'javascript', 'jquery', 'asp', 'sql', 'windows', 'ruby']\n"
     ]
    }
   ],
   "source": [
    "print(tag_matrix.shape)\n",
    "print(tag_matrix)\n",
    "print(list(tag_tokenizer.word_index.keys())[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[[0.         1.65506803 2.11881721 ... 0.         0.         0.        ]\n",
      " [0.         1.65506803 1.28502094 ... 0.         0.         0.        ]]\n",
      "['p', 'the', 'i', 'to', 'code', 'a', 'gt', 'lt', 'is', 'and', 'pre', 'in', 'of', 'this', 'it', 'that', '0', '1', 'for', 'have', 'my', 'if', 'on', 'but', 'with']\n",
      "['listbox', 'repo', 'python2', 'criteria', 'rvm', '42', 'logo', 'traffic', 'her', 'exceptions', 'radius', 'thumbnail', 'inputstream', 'efficient', 'agent', 'x81', 'webpage', 'friend', 'movie', '404', 'databases', 'actions', 'settext', 'suggestion', 'removing']\n"
     ]
    }
   ],
   "source": [
    "text_tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "text_tokenizer.fit_on_texts(text_list)\n",
    "text_matrix = text_tokenizer.texts_to_matrix(text_list, mode='tfidf')\n",
    "\n",
    "# We have a numeric representation of the words in the questions\n",
    "print(vocab_size)\n",
    "print(text_matrix[:2])\n",
    "print(list(text_tokenizer.word_index.keys())[:25])\n",
    "print(list(text_tokenizer.word_index.keys())[vocab_size-25:vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padd all sequences to the same size\n",
    "y = tag_matrix\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(text_matrix, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2000)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Multi Logistic Regression Model\n",
    "log_reg_model = Sequential()\n",
    "log_reg_model.add(Dense(n_top_tags, activation='sigmoid', input_shape=(vocab_size, )))\n",
    "log_reg_model.compile(optimizer=SGD(), loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 8)                 16008     \n",
      "=================================================================\n",
      "Total params: 16,008\n",
      "Trainable params: 16,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "log_reg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 2s 102us/step - loss: 0.3560 - acc: 0.8911\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 1s 41us/step - loss: 0.2666 - acc: 0.9283\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 1s 42us/step - loss: 0.2383 - acc: 0.9321\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 1s 41us/step - loss: 0.2202 - acc: 0.9355\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 1s 42us/step - loss: 0.2072 - acc: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139629f60>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32375979 0.29441624 0.29765013 0.54166667 0.37823834 0.27210884\n",
      " 0.4516129  0.19138756]\n",
      "0.34385506006665667\n"
     ]
    }
   ],
   "source": [
    "log_reg_score = f1_score(y_val, log_reg_model.predict(x_val) > 0.5, average=None)\n",
    "print(log_reg_score)\n",
    "print(np.mean(log_reg_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[[1, 383, 50, 4, 376, 22, 34, 54, 9, 34, 141, 54, 92, 304, 344, 472, 1435, 42, 253, 54, 2, 98, 9, 16, 51, 46, 4, 783, 2, 170, 63, 609, 2, 79, 10, 782, 6, 42, 157, 28, 2, 79, 100, 1325, 63, 54, 79, 82, 783, 1, 1, 9, 55, 6, 85, 4, 376, 22, 2, 54, 9, 34, 141, 30, 1192, 2, 54, 1058, 46, 108, 1], [1, 12, 21, 1170, 3, 69, 510, 4, 581, 6, 841, 306, 134, 15, 979, 1607, 807, 4, 83, 16, 1009, 9, 2, 812, 343, 23, 181, 235, 3, 298, 478, 38, 991, 9, 2, 812, 343, 10, 1381, 510, 63, 1009, 14, 9, 26, 58, 3, 64, 9, 55, 6, 85, 4, 708, 510, 30, 1009, 1, 1, 1]]\n",
      "['p', 'the', 'i', 'to', 'code', 'a', 'gt', 'lt', 'is', 'and', 'pre', 'in', 'of', 'this', 'it', 'that', '0', '1', 'for', 'have', 'my', 'if', 'on', 'but', 'with']\n",
      "['listbox', 'repo', 'python2', 'criteria', 'rvm', '42', 'logo', 'traffic', 'her', 'exceptions', 'radius', 'thumbnail', 'inputstream', 'efficient', 'agent', 'x81', 'webpage', 'friend', 'movie', '404', 'databases', 'actions', 'settext', 'suggestion', 'removing']\n"
     ]
    }
   ],
   "source": [
    "text_tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "text_tokenizer.fit_on_texts(text_list)\n",
    "text_matrix = text_tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "# We have a numeric representation of the words in the questions\n",
    "print(vocab_size)\n",
    "print(text_matrix[:2])\n",
    "print(list(text_tokenizer.word_index.keys())[:25])\n",
    "print(list(text_tokenizer.word_index.keys())[vocab_size-25:vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padd all sequences to the same size\n",
    "X = sequence.pad_sequences(text_matrix, maxlen=max_length, padding='pre', truncating='post')\n",
    "\n",
    "y = tag_matrix\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a sequence model instead\n",
    "seq_model = Sequential()\n",
    "seq_model.add(Embedding(vocab_size, 100, input_shape=(max_length, )))\n",
    "seq_model.add(Dropout(.2))\n",
    "seq_model.add(LSTM(64))\n",
    "seq_model.add(Dropout(.2))\n",
    "seq_model.add(Dense(n_top_tags, activation='sigmoid'))\n",
    "seq_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 350, 100)          200000    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 350, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 242,760\n",
      "Trainable params: 242,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 154s 10ms/step - loss: 0.2741 - acc: 0.9247\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 159s 10ms/step - loss: 0.2444 - acc: 0.9280\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 155s 10ms/step - loss: 0.1972 - acc: 0.9289\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 149s 9ms/step - loss: 0.1649 - acc: 0.9382\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 156s 10ms/step - loss: 0.1443 - acc: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17072c1d0>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33423181 0.53053435 0.49115044 0.78100264 0.58823529 0.51327434\n",
      " 0.57788945 0.58381503]\n",
      "0.5500166680767511\n"
     ]
    }
   ],
   "source": [
    "seq_score = f1_score(y_val, seq_model.predict(x_val) > 0.5, average=None)\n",
    "print(seq_score)\n",
    "print(np.mean(seq_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
